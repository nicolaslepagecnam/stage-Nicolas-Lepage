{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test problem 2: Flow past a cylinder (DFG 2D-3 benchmark)\n",
    "Author: Jørgen S. Dokken\n",
    "\n",
    "In this section, we will turn our attention to a slightly more challenging problem: flow past a cylinder. The geometry and parameters are taken from the [DFG 2D-3 benchmark](http://www.featflow.de/en/benchmarks/cfdbenchmarking/flow/dfg_benchmark3_re100.html) in FeatFlow.\n",
    "\n",
    "To be able to solve this problem efficiently and ensure numerical stability, we will subsitute our first order backward difference scheme with a second order backward difference approximation, and use an explicit Adams-Bashforth approximation of the non-linear term.\n",
    "\n",
    "```{admonition} Computationally demanding demo\n",
    "This demo is computationally demanding, with a run-time up to 25 minutes, as it is using parameters from the DFG 2D-3 benchmark, which consists of 12800 time steps. It is adviced to download this demo and  not run it in a browser. Please also see the last part of the tutorial on how to use `mpirun` to speedup the run-time of the program.\n",
    "```\n",
    "\n",
    "The computational geometry we would like to use is\n",
    "![Fluid channel with a circular obstacle](turek.png)\n",
    "\n",
    "The kinematic velocity is given by $\\nu=0.001=\\frac{\\mu}{\\rho}$ and the inflow velocity profile is specified as\n",
    "\n",
    "$$\n",
    "    u(x,y,t) = \\left( \\frac{4Uy(0.41-y)}{0.41^2}, 0 \\right)\n",
    "$$\n",
    "$$\n",
    "    U=U(t) = 1.5\\sin(\\pi t/8)\n",
    "$$\n",
    "\n",
    "which has a maximum magnitude of $1.5$ at $y=0.41/2$. We do not use any scaling for this problem since all exact parameters are known. \n",
    "## Mesh generation\n",
    "As in the [Deflection of a membrane](./../chapter1/membrane_code.ipynb) we use GMSH to generate the mesh. We fist create the rectangle and obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (4.63.1)\n",
      "Requirement already satisfied: mpi4py in /usr/local/lib/python3.9/dist-packages (3.1.3)\n",
      "Requirement already satisfied: petsc4py in /usr/local/lib/python3.9/dist-packages (3.16.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from petsc4py) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n",
    "!pip install mpi4py\n",
    "!pip install petsc4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gmsh\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm.notebook\n",
    "\n",
    "import numpy.typing\n",
    "import typing\n",
    "\n",
    "from mpi4py import MPI\n",
    "from petsc4py import PETSc\n",
    "\n",
    "from dolfinx.cpp.mesh import to_type, cell_entity_type\n",
    "from dolfinx.fem import Constant, Function, FunctionSpace, assemble_scalar, dirichletbc, form, locate_dofs_topological, set_bc\n",
    "from dolfinx.fem.petsc import apply_lifting, assemble_matrix, assemble_vector, create_vector, set_bc\n",
    "from dolfinx.graph import create_adjacencylist\n",
    "from dolfinx.geometry import BoundingBoxTree, compute_collisions, compute_colliding_cells\n",
    "from dolfinx.io import (XDMFFile, cell_perm_gmsh, distribute_entity_data, extract_gmsh_geometry,\n",
    "                        extract_gmsh_topology_and_markers, ufl_mesh_from_gmsh)\n",
    "from dolfinx.mesh import create_mesh, meshtags_from_entities\n",
    "\n",
    "import ufl\n",
    "\n",
    "from ufl import (FacetNormal, FiniteElement, Identity, Measure, TestFunction, TrialFunction, VectorElement,\n",
    "                 as_vector, div, dot, ds, dx, inner, lhs, grad, nabla_grad, rhs, sym)\n",
    "\n",
    "gmsh.initialize()\n",
    "\n",
    "L = 2.2\n",
    "H = 0.41\n",
    "c_x = c_y =0.2\n",
    "r = 0.05\n",
    "gdim = 2\n",
    "rank = MPI.COMM_WORLD.rank\n",
    "if rank == 0:\n",
    "    rectangle = gmsh.model.occ.addRectangle(0,0,0, L, H, tag=1)\n",
    "    obstacle = gmsh.model.occ.addDisk(c_x, c_y, 0, r, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to subtract the obstacle from the channel, such that we do not mesh the interior of the circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if rank == 0:\n",
    "    fluid = gmsh.model.occ.cut([(gdim, rectangle)], [(gdim, obstacle)])\n",
    "    gmsh.model.occ.synchronize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get GMSH to mesh the fluid, we add a physical volume marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluid_marker = 1\n",
    "if rank == 0:\n",
    "    volumes = gmsh.model.getEntities(dim=gdim)\n",
    "    gmsh.model.addPhysicalGroup(volumes[0][0], [volumes[0][1]], fluid_marker)\n",
    "    gmsh.model.setPhysicalName(volumes[0][0], fluid_marker, \"Fluid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tag the different surfaces of the mesh, we tag the inflow (left hand side) with marker 2, the outflow (right hand side) with marker 3 and the fluid walls with 4 and obstacle with 5. We will do this by compute the center of mass for each geometrical entitiy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inlet_marker, outlet_marker, wall_marker, obstacle_marker = 2, 3, 4, 5\n",
    "inflow, outflow, walls, obstacle = [], [], [], []\n",
    "if rank == 0:\n",
    "    boundaries = gmsh.model.getBoundary(volumes, oriented=False)\n",
    "    for boundary in boundaries:\n",
    "        center_of_mass = gmsh.model.occ.getCenterOfMass(boundary[0], boundary[1])\n",
    "        if np.allclose(center_of_mass, [0, H/2, 0]):\n",
    "            inflow.append(boundary[1])\n",
    "        elif np.allclose(center_of_mass, [L, H/2, 0]):\n",
    "            outflow.append(boundary[1])\n",
    "        elif np.allclose(center_of_mass, [L/2, H, 0]) or np.allclose(center_of_mass, [L/2, 0, 0]):\n",
    "            walls.append(boundary[1])\n",
    "        else:\n",
    "            obstacle.append(boundary[1])\n",
    "    gmsh.model.addPhysicalGroup(1, walls, wall_marker)\n",
    "    gmsh.model.setPhysicalName(1, wall_marker, \"Walls\")\n",
    "    gmsh.model.addPhysicalGroup(1, inflow, inlet_marker)\n",
    "    gmsh.model.setPhysicalName(1, inlet_marker, \"Inlet\")\n",
    "    gmsh.model.addPhysicalGroup(1, outflow, outlet_marker)\n",
    "    gmsh.model.setPhysicalName(1, outlet_marker, \"Outlet\")\n",
    "    gmsh.model.addPhysicalGroup(1, obstacle, obstacle_marker)\n",
    "    gmsh.model.setPhysicalName(1, obstacle_marker, \"Obstacle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous meshes, we have used uniform mesh sizes. In this example, we will have variable mesh sizes to resolve the flow solution in  the area of interest; close to the circular obstacle. To do this, we use GMSH Fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distance field from obstacle.\n",
    "# Add threshold of mesh sizes based on the distance field\n",
    "# LcMax -                  /--------\n",
    "#                      /\n",
    "# LcMin -o---------/\n",
    "#        |         |       |\n",
    "#       Point    DistMin DistMax\n",
    "res_min = r / 2.5 #3.7\n",
    "res_max = 2 * r\n",
    "if rank == 0:\n",
    "    gmsh.model.mesh.field.add(\"Distance\", 1)\n",
    "    gmsh.model.mesh.field.setNumbers(1, \"EdgesList\", obstacle)\n",
    "    gmsh.model.mesh.field.add(\"Threshold\", 2)\n",
    "    gmsh.model.mesh.field.setNumber(2, \"IField\", 1)\n",
    "    gmsh.model.mesh.field.setNumber(2, \"LcMin\", res_min)\n",
    "    gmsh.model.mesh.field.setNumber(2, \"LcMax\", res_max)\n",
    "    gmsh.model.mesh.field.setNumber(2, \"DistMin\", 4*r)\n",
    "    gmsh.model.mesh.field.setNumber(2, \"DistMax\", 8*r)\n",
    "\n",
    "    # We take the minimum of the two fields as the mesh size\n",
    "    gmsh.model.mesh.field.add(\"Min\", 5)\n",
    "    gmsh.model.mesh.field.setNumbers(5, \"FieldsList\", [2])\n",
    "    gmsh.model.mesh.field.setAsBackgroundMesh(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the mesh\n",
    "We are now ready to generate the mesh. However, we have to decide if our mesh should consist of triangles or quadrilaterals. In this demo, to match the DFG 2D-3 benchmark, we use quadrilateral elements. This is done by recombining the mesh, setting three gmsh options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info    : Meshing 1D...\n",
      "Info    : [  0%] Meshing curve 5 (Ellipse)\n",
      "Info    : [ 20%] Meshing curve 6 (Line)\n",
      "Info    : [ 40%] Meshing curve 7 (Line)\n",
      "Info    : [ 60%] Meshing curve 8 (Line)\n",
      "Info    : [ 80%] Meshing curve 9 (Line)\n",
      "Info    : Done meshing 1D (Wall 0.0209511s, CPU 0.026908s)\n",
      "Info    : Meshing 2D...\n",
      "Info    : Meshing surface 1 (Plane, Frontal-Delaunay)\n",
      "Info    : Simple recombination completed (Wall 0.0100857s, CPU 0s): 561 quads, 194 triangles, 0 invalid quads, 0 quads with Q < 0.1, avg Q = 0.76323, min Q = 0.454642\n",
      "Info    : Done meshing 2D (Wall 0.0378781s, CPU 0.030614s)\n",
      "Info    : Refining mesh...\n",
      "Info    : Meshing order 2 (curvilinear on)...\n",
      "Info    : [  0%] Meshing curve 5 order 2\n",
      "Info    : [ 20%] Meshing curve 6 order 2\n",
      "Info    : [ 40%] Meshing curve 7 order 2\n",
      "Info    : [ 50%] Meshing curve 8 order 2\n",
      "Info    : [ 70%] Meshing curve 9 order 2\n",
      "Info    : [ 90%] Meshing surface 1 order 2\n",
      "Info    : Surface mesh: worst distortion = 0.787378 (0 elements in ]0, 0.2]); worst gamma = 0.861218\n",
      "Info    : Done meshing order 2 (Wall 0.0073086s, CPU 0.010396s)\n",
      "Info    : Done refining mesh (Wall 0.0084497s, CPU 0.011955s)\n",
      "Info    : 2944 nodes 3067 elements\n",
      "Info    : Optimizing mesh (Netgen)...\n",
      "Info    : Done optimizing mesh (Wall 1.20001e-06s, CPU 4e-06s)\n"
     ]
    }
   ],
   "source": [
    "if rank == 0:\n",
    "    gmsh.option.setNumber(\"Mesh.RecombinationAlgorithm\", 8)\n",
    "    gmsh.option.setNumber(\"Mesh.RecombineAll\", 2)\n",
    "    gmsh.option.setNumber(\"Mesh.SubdivisionAlgorithm\", 1)\n",
    "    gmsh.model.mesh.generate(gdim)\n",
    "    gmsh.model.mesh.optimize(\"Netgen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading mesh and boundary markers\n",
    "As we have generated the mesh, we now need to load the mesh and corresponding facet markers into DOLFINx.\n",
    "To load the mesh, we follow the same structure as in  [Deflection of a membrane](./../chapter1/membrane_code.ipynb), with slight modifications to include the facet markers. To learn more about the specifics of the function below, see [A GMSH tutorial for DOLFINx](http://jsdokken.com/converted_files/tutorial_gmsh.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if MPI.COMM_WORLD.rank == 0:\n",
    "    # Get mesh geometry\n",
    "    \n",
    "    x = extract_gmsh_geometry(gmsh.model)\n",
    "\n",
    "    # Get mesh topology for each element\n",
    "    topologies = extract_gmsh_topology_and_markers(gmsh.model)\n",
    "    # Get information about each cell type from the msh files\n",
    "    num_cell_types = len(topologies.keys())\n",
    "    cell_information = {}\n",
    "    cell_dimensions = np.zeros(num_cell_types, dtype=np.int32)\n",
    "    for i, element in enumerate(topologies.keys()):\n",
    "        properties = gmsh.model.mesh.getElementProperties(element)\n",
    "        name, dim, order, num_nodes, local_coords, _ = properties\n",
    "        cell_information[i] = {\"id\": element, \"dim\": dim, \"num_nodes\": num_nodes}\n",
    "        cell_dimensions[i] = dim\n",
    "\n",
    "    # Sort elements by ascending dimension\n",
    "    perm_sort = np.argsort(cell_dimensions)\n",
    "\n",
    "    # Broadcast cell type data and geometric dimension\n",
    "    cell_id = cell_information[perm_sort[-1]][\"id\"]\n",
    "    tdim = cell_information[perm_sort[-1]][\"dim\"]\n",
    "    num_nodes = cell_information[perm_sort[-1]][\"num_nodes\"]\n",
    "    cell_id, num_nodes = MPI.COMM_WORLD.bcast([cell_id, num_nodes], root=0)\n",
    "    if tdim - 1 in cell_dimensions:\n",
    "        num_facet_nodes = MPI.COMM_WORLD.bcast( cell_information[perm_sort[-2]][\"num_nodes\"], root=0)\n",
    "        gmsh_facet_id = cell_information[perm_sort[-2]][\"id\"]\n",
    "        marked_facets = np.asarray(topologies[gmsh_facet_id][\"topology\"], dtype=np.int64)\n",
    "        facet_values = np.asarray(topologies[gmsh_facet_id][\"cell_data\"], dtype=np.int32)\n",
    "\n",
    "    cells = np.asarray(topologies[cell_id][\"topology\"], dtype=np.int64)\n",
    "    cell_values = np.asarray(topologies[cell_id][\"cell_data\"], dtype=np.int32)\n",
    "\n",
    "else:\n",
    "    cell_id, num_nodes = MPI.COMM_WORLD.bcast([None, None], root=0)\n",
    "    cells, x = np.empty([0, num_nodes], np.int64), np.empty([0, gdim])\n",
    "    cell_values = np.empty((0,), dtype=np.int32)\n",
    "    num_facet_nodes = MPI.COMM_WORLD.bcast(None, root=0)\n",
    "    marked_facets = np.empty((0, num_facet_nodes), dtype=np.int64)\n",
    "    facet_values = np.empty((0,), dtype=np.int32)\n",
    "\n",
    "# Create distributed mesh\n",
    "ufl_domain = ufl_mesh_from_gmsh(cell_id, gdim)\n",
    "gmsh_cell_perm = cell_perm_gmsh(to_type(str(ufl_domain.ufl_cell())), num_nodes)\n",
    "cells = cells[:, gmsh_cell_perm]\n",
    "mesh = create_mesh(MPI.COMM_WORLD, cells, x[:, :gdim], ufl_domain)\n",
    "tdim = mesh.topology.dim\n",
    "fdim = tdim - 1\n",
    "# Permute facets from MSH to DOLFINx ordering\n",
    "# FIXME: Last argument is 0 as all facets are the same for tetrahedra\n",
    "facet_type = cell_entity_type(to_type(str(ufl_domain.ufl_cell())), fdim, 0)\n",
    "gmsh_facet_perm = cell_perm_gmsh(facet_type, num_facet_nodes)\n",
    "marked_facets = np.asarray(marked_facets[:, gmsh_facet_perm], dtype=np.int64)\n",
    "\n",
    "local_entities, local_values = distribute_entity_data(mesh, fdim, marked_facets, facet_values)\n",
    "mesh.topology.create_connectivity(fdim, tdim)\n",
    "adj = create_adjacencylist(local_entities)\n",
    "# Create DOLFINx MeshTags\n",
    "ft = meshtags_from_entities(mesh, fdim, adj, np.int32(local_values))\n",
    "ft.name = \"Facet tags\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physical and discretization parameters\n",
    "Following the DGF-2 benchmark, we define our problem specific parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "T = 8 #8                    # Final time\n",
    "dt = 1/4000              # Time step size\n",
    "num_steps = int(T/dt)\n",
    "k = Constant(mesh, PETSc.ScalarType(dt))        \n",
    "mu = Constant(mesh, PETSc.ScalarType(0.001))  # Dynamic viscosity\n",
    "nu = Constant(mesh, PETSc.ScalarType(0.001)) \n",
    "rho = Constant(mesh, PETSc.ScalarType(1))     # Density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{admonition} Reduced end-time of problem\n",
    "In the current demo, we have reduced the run time to one second to make it easier to illustrate the concepts of the benchmark. By increasing the end-time `T` to 8, the runtime in a notebook is approximately 25 minutes. If you convert the notebook to a python file and use `mpirun`, you can reduce the runtime of the problem.\n",
    "```\n",
    "\n",
    "## Boundary conditions\n",
    "As we have created the mesh and relevant mesh tags, we can now specify the function spaces `V` and `Q` along with the boundary conditions. As the `ft` contains markers for facets, we use this class to find the facets for the inlet and walls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cg2 = VectorElement(\"CG\", mesh.ufl_cell(), 2)\n",
    "s_cg1 = FiniteElement(\"CG\", mesh.ufl_cell(), 1)\n",
    "W_element = ufl.MixedElement(v_cg2, s_cg1)\n",
    "W = FunctionSpace(mesh, W_element)\n",
    "\n",
    "\n",
    "fdim = mesh.topology.dim - 1\n",
    "\n",
    "# Define boundary conditions\n",
    "class InletVelocity():\n",
    "    def __init__(self, t):\n",
    "        self.t = t\n",
    "\n",
    "    def __call__(self, x):\n",
    "        values = np.zeros((gdim, x.shape[1]),dtype=PETSc.ScalarType)\n",
    "        values[0] = 4 * 1.5 * np.sin(self.t * np.pi/8) * x[1] * (0.41 - x[1])/(0.41**2)\n",
    "        return values\n",
    "\n",
    "# Inlet\n",
    "u_inlet_truc = Function(W)\n",
    "u_inlet,_ = u_inlet_truc.split()\n",
    "inlet_velocity = InletVelocity(t)\n",
    "u_inlet.interpolate(inlet_velocity)\n",
    "inlet_facets = ft.indices[ft.values == inlet_marker]\n",
    "\n",
    "bcu_inflow = dirichletbc(u_inlet, locate_dofs_topological(W.sub(0), fdim, inlet_facets))\n",
    "\n",
    "u_nonslip = np.array((0,) *mesh.geometry.dim, dtype=PETSc.ScalarType)\n",
    "wall_facets = ft.indices[ft.values == wall_marker]\n",
    "bcu_walls = dirichletbc(u_nonslip, locate_dofs_topological(W.sub(0), fdim, wall_facets), W.sub(0))\n",
    "# Obstacle\n",
    "obstacle_facets = ft.indices[ft.values == obstacle_marker]\n",
    "bcu_obstacle = dirichletbc(u_nonslip, locate_dofs_topological(W.sub(0), fdim, obstacle_facets), W.sub(0))\n",
    "bcu = [bcu_inflow, bcu_obstacle, bcu_walls]\n",
    "# Outlet\n",
    "outlet_facets = ft.indices[ft.values == outlet_marker]\n",
    "bcp_outlet = dirichletbc(PETSc.ScalarType(0), locate_dofs_topological(W.sub(1), fdim, outlet_facets), W.sub(1))\n",
    "bcp = [bcp_outlet]\n",
    "\n",
    "bc = [bcu_inflow, bcu_obstacle, bcu_walls, bcp_outlet]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variational form\n",
    "As opposed to [Pouseille flow](./ns_code1.ipynb), we will use a Crank-Nicolson discretization, and an explicit Adams-Bashforth approximation.\n",
    "The first step can be written as\n",
    "\n",
    "$$\n",
    "\\rho\\left(\\frac{u^*- u^n}{\\delta t} + \\frac{3}{2} u^n \\cdot \\nabla u^n - \\frac{1}{2} u^{n-1} \\cdot \\nabla u^{n-1}\\right) - \\frac{1}{2}\\mu \\Delta( u^*+ u^n )+ \\nabla p^{n-1/2} = f^{n+\\frac{1}{2}} \\qquad \\text{ in } \\Omega\n",
    "$$\n",
    "\n",
    "$$\n",
    "u^{*}=g(\\cdot, t^{n+1}) \\qquad \\text{ on } \\partial \\Omega_{D}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{1}{2}\\nu \\nabla (u^*+u^n) \\cdot n = p^{n-\\frac{1}{2}} \\qquad \\text{ on } \\partial \\Omega_{N}\n",
    "$$\n",
    "where we have used the two previous time steps in the temporal derivative for the velocity, and compute the pressure staggered in time, at the time between the previous and current solution. The second step becomes\n",
    "$$\n",
    "-\\nabla \\phi = -\\frac{1}{\\delta t} \\nabla \\cdot u^* \\qquad\\text{in } \\Omega,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\nabla \\phi \\cdot n = 0 \\qquad \\text{on } \\partial \\Omega_D,\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\phi = 0 \\qquad\\text{on } \\partial\\Omega_N\n",
    "$$\n",
    "\n",
    "where $p^{n+\\frac{1}{2}}=p^{n-\\frac{1}{2}} + \\phi$.\n",
    "Finally, the third step is\n",
    "\n",
    "$$\n",
    "u^{n+1} = u^{*}-\\delta t \\phi. \n",
    "$$\n",
    "\n",
    "We start by defining all the variables used in the variational formulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolfinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u = TrialFunction(V)\n",
    "# v = TestFunction(V)\n",
    "# u_ = Function(V)\n",
    "# u_.name = \"u\"\n",
    "# u_s = Function(V)\n",
    "# u_n = Function(V)\n",
    "# u_n1 = Function(V)\n",
    "# p = TrialFunction(Q)\n",
    "# q = TestFunction(Q)\n",
    "# p_ = Function(Q)\n",
    "# p_.name = \"p\"\n",
    "# phi = Function(Q)\n",
    "\n",
    "\n",
    "# Define trial and test functions\n",
    "\n",
    "u_n1p_n1 = TrialFunction(W)\n",
    "u_n1,p_n1 = ufl.split(u_n1p_n1)\n",
    "\n",
    "vq = TestFunction(W)\n",
    "v,q = ufl.split(vq)\n",
    "\n",
    "# Define functions for solutions at previous and current time steps\n",
    "u_np_n = Function(W)\n",
    "u_n,p_n = u_np_n.split()\n",
    "\n",
    "\n",
    "# Define expressions used in variational forms\n",
    "n  = FacetNormal(mesh)\n",
    "k  = Constant(mesh, PETSc.ScalarType((dt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the variational formulation for the first step, where we have integrated the diffusion term, as well as the pressure term by parts. As we have used an explicit approximation of the non-linear term we only have to assemble the matrix once, but we have to save the two previous solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = Constant(mesh, PETSc.ScalarType((0,0)))\n",
    "# F1 = rho / k * dot(u - u_n, v) * dx \n",
    "# F1 += inner(1.5 * dot(u_n, nabla_grad(u_n)) - 0.5 * dot(u_n1, nabla_grad(u_n1)), v) * dx\n",
    "# F1 += 0.5 * mu * inner(grad(u+u_n), grad(v))*dx - dot(p_, div(v))*dx\n",
    "# F1 += dot(f, v) * dx\n",
    "# a1 = form(lhs(F1))\n",
    "# L1 = form(rhs(F1))\n",
    "# A1 = assemble_matrix(a1, bcs=bcu)\n",
    "# A1.assemble()\n",
    "# b1 = create_vector(L1)\n",
    "\n",
    "\n",
    "# # Define symmetric gradient\n",
    "# def epsilon(u):\n",
    "#     return sym(nabla_grad(u))\n",
    "\n",
    "# # Define stress tensor\n",
    "# def sigma(u, p):\n",
    "#     return 2*mu*epsilon(u) - p*Identity(len(u))\n",
    "\n",
    "# # Define variational problem for step 1\n",
    "# # F1 = rho*dot((u - u_n) / k, v)*dx + rho*dot(dot(u_n, nabla_grad(u_n)), v)*dx + inner(sigma(U, p_n), epsilon(v))*dx  + dot(p_n*n, v)*ds - dot(mu*nabla_grad(U)*n, v)*ds - dot(f, v)*dx\n",
    "# # F1 = (1/k)*inner(u - u_n, v)*dx + inner(grad(u_n)*u_n, v)*dx + nu*inner(grad(u), grad(v))*dx - inner(f, v)*dx\n",
    "# F1 = (1/k)*inner(u - u_n, v)*dx + inner(grad(u_n)*b, v)*dx + nu*inner(grad(u), grad(v))*dx - inner(f, v)*dx\n",
    "# # F1 = (1/k)*inner(u - u_n, v)*dx + nu*inner(grad(u), grad(v))*dx - inner(f, v)*dx\n",
    "# a1 = form(lhs(F1))\n",
    "# L1 = form(rhs(F1))\n",
    "\n",
    "### directly solving navier stokes\n",
    "\n",
    "F = ((1/k)*inner(u_n1 - u_n, v)*dx\n",
    "    + inner(ufl.grad(u_n) * u_n, v) * dx \n",
    "    + nu * inner(ufl.grad(u_n1), ufl.grad(v)) * dx\n",
    "    + inner(ufl.div(u_n1), q) * dx\n",
    "    - inner(p_n1, ufl.div(v)) * dx)\n",
    "\n",
    "a = form(lhs(F))\n",
    "L = form(rhs(F))\n",
    "A = assemble_matrix(a, bcs=bc)\n",
    "A.assemble()\n",
    "b = create_vector(L)  \n",
    "\n",
    "solver1 = PETSc.KSP().create(mesh.comm)\n",
    "solver1.setOperators(A)\n",
    "solver1.setType(PETSc.KSP.Type.BCGS)\n",
    "pc1 = solver1.getPC()\n",
    "pc1.setType(PETSc.PC.Type.JACOBI)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous tutorials, we use PETSc as a linear algebra backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification of the implementation compute known physical quantities\n",
    "As a further verification of our implementation, we compute the drag and lift coefficients over the obstacle, defined as\n",
    "\n",
    "$$\n",
    "    C_{\\text{D}}(u,p,t,\\partial\\Omega_S) = \\frac{2}{\\rho L U_{mean}^2}\\int_{\\partial\\Omega_S}\\rho \\nu n \\cdot \\nabla u_{t_S}(t)n_y -p(t)n_x~\\mathrm{d} s,\n",
    "$$    \n",
    "$$ \n",
    "    C_{\\text{L}}(u,p,t,\\partial\\Omega_S) = -\\frac{2}{\\rho L U_{mean}^2}\\int_{\\partial\\Omega_S}\\rho \\nu n \\cdot \\nabla u_{t_S}(t)n_x + p(t)n_y~\\mathrm{d} s,\n",
    "$$\n",
    "\n",
    "where $u_{t_S}$ is the tangential velocity component at the interface of the obstacle $\\partial\\Omega_S$, defined as $u_{t_S}=u\\cdot (n_y,-n_x)$, $U_{mean}=1$ the average inflow velocity, and $L$ the length of the channel. We use `UFL` to create the relevant integrals, and assemble them at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = -FacetNormal(mesh) # Normal pointing out of obstacle\n",
    "# dObs = Measure(\"ds\", domain=mesh, subdomain_data=ft, subdomain_id=obstacle_marker)\n",
    "# u_t = inner(as_vector((n[1], -n[0])), u_)\n",
    "# drag = form(2 / 0.1 * (mu / rho * inner(grad(u_t), n) * n[1] - p_ * n[0]) * dObs)\n",
    "# lift = form(-2 / 0.1 * (mu / rho * inner(grad(u_t), n) * n[0] + p_ * n[1]) * dObs)\n",
    "# if rank == 0:\n",
    "#     C_D = np.zeros(num_steps, dtype=PETSc.ScalarType)\n",
    "#     C_L = np.zeros(num_steps, dtype=PETSc.ScalarType)\n",
    "#     t_u = np.zeros(num_steps, dtype=np.float64)\n",
    "#     t_p = np.zeros(num_steps, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also evaluate the pressure at two points, on in front of the obstacle, $(0.15, 0.2)$, and one behind the obstacle, $(0.25, 0.2)$. To do this, we have to find which cell is containing each of the points, so that we can create a linear combination of the local basis functions and coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree = BoundingBoxTree(mesh, mesh.geometry.dim)\n",
    "# points = np.array([[0.15, 0.2, 0], [0.25, 0.2, 0]])\n",
    "# cell_candidates = compute_collisions(tree, points)\n",
    "# colliding_cells = compute_colliding_cells(mesh, cell_candidates, points)\n",
    "# front_cells = colliding_cells.links(0)\n",
    "# back_cells = colliding_cells.links(1)\n",
    "# if rank == 0:\n",
    "#     p_diff = np.zeros(num_steps, dtype=PETSc.ScalarType)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the time-dependent problem\n",
    "```{admonition} Stability of the Navier-Stokes equation\n",
    "Note that the current splitting scheme has to fullfil the a [Courant–Friedrichs–Lewy condition](https://en.wikipedia.org/wiki/Courant%E2%80%93Friedrichs%E2%80%93Lewy_condition). This limits the spatial discretization with respect to the inlet velocity and temporal discretization.\n",
    "Other temporal discretization schemes such as the second order backward difference discretization or Crank-Nicholson discretization with Adams-Bashforth linearization are better behaved than our simple backward differnce scheme.```\n",
    "As in the previous example, we create output files for the velocity and pressure and solve the time-dependent problem. As we are solving a time dependent problem with many time steps, we use the `tqdm`-package to visualize the progress. This package can be install with `pip3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff52eca89a8f432cb66319286ea2c029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Solving PDE:   0%|          | 0/32000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# xdmf = XDMFFile(MPI.COMM_WORLD, \"dfg2D-3.xdmf\", \"w\")\n",
    "# xdmf.write_mesh(mesh)\n",
    "# xdmf.write_function(u_, t)\n",
    "# xdmf.write_function(p_, t)\n",
    "\n",
    "# def create_snes_solution(solution) -> PETSc.Vec:\n",
    "#         \"\"\"\n",
    "#         Create a petsc4py.PETSc.Vec to be passed to petsc4py.PETSc.SNES.solve.\n",
    "\n",
    "#         The returned vector will be initialized with the initial guess provided in `self._solution`.\n",
    "#         \"\"\"\n",
    "#         x = solution.vector.copy()\n",
    "#         with x.localForm() as _x, solution.vector.localForm() as _solution:\n",
    "#             _x[:] = _solution\n",
    "#         return x\n",
    "\n",
    "list_u = []\n",
    "\n",
    "list_p = []\n",
    "\n",
    "up_temp =Function(W)\n",
    "\n",
    "progress = tqdm.notebook.tqdm(desc=\"Solving PDE\", total=num_steps)\n",
    "# If running this as a python script, you should use the Progressbar command below\n",
    "# progress = tqdm.tqdm(desc=\"Solving PDE\", total=num_steps)\n",
    "for i in range(num_steps):\n",
    "    progress.update(1)\n",
    "    # Update current time step\n",
    "    t += dt\n",
    "    # Update inlet velocity\n",
    "    inlet_velocity.t = t\n",
    "    u_inlet.interpolate(inlet_velocity)\n",
    "    \n",
    "     # Step 1: Tentative veolcity step\n",
    "    with b.localForm() as loc:\n",
    "        loc.set(0)\n",
    "    assemble_vector(b, L)\n",
    "    apply_lifting(b, [a], [bc])\n",
    "    b.ghostUpdate(addv=PETSc.InsertMode.ADD_VALUES, mode=PETSc.ScatterMode.REVERSE)\n",
    "    set_bc(b, bc)\n",
    "    solver1.solve(b, up_temp.vector)\n",
    "    up_temp.x.scatter_forward()\n",
    "    \n",
    "    # create solutions list for vtk plot\n",
    "    \n",
    "    if i%200 == 0 :\n",
    "        (u_f, p_f) = (up_temp.sub(0).collapse(), up_temp.sub(1).collapse())\n",
    "        list_u.append(u_f.copy())\n",
    "        list_p.append(p_f.copy())\n",
    "\n",
    "    # Update variable with solution form this time step\n",
    "    with up_temp.vector.localForm() as loc_u, u_np_n.vector.localForm() as loc_un:\n",
    "        loc_u.copy(loc_un)\n",
    "\n",
    "    # # Compute physical quantities\n",
    "    # # For this to work in paralell, we gather contributions from all processors\n",
    "    # # to processor zero and sum the contributions. \n",
    "    # drag_coeff = MPI.COMM_WORLD.gather(assemble_scalar(drag), root=0)\n",
    "    # lift_coeff = MPI.COMM_WORLD.gather(assemble_scalar(lift), root=0)\n",
    "    # p_front = None\n",
    "    # if len(front_cells) > 0:\n",
    "    #     p_front = p_.eval(points[0], front_cells[:1])\n",
    "    # p_front = MPI.COMM_WORLD.gather(p_front, root=0)\n",
    "    # p_back = None\n",
    "    # if len(back_cells) > 0:\n",
    "    #     p_back = p_.eval(points[1], back_cells[:1])\n",
    "    # p_back = MPI.COMM_WORLD.gather(p_back, root=0)\n",
    "    # if rank == 0:\n",
    "    #     t_u[i] = t\n",
    "    #     t_p[i] = t-dt/2\n",
    "    #     C_D[i] = sum(drag_coeff)\n",
    "    #     C_L[i] = sum(lift_coeff)\n",
    "    #     # Choose first pressure that is found from the different processors\n",
    "    #     for pressure in p_front:\n",
    "    #         if pressure is not None:\n",
    "    #             p_diff[i] = pressure[0]\n",
    "    #             break\n",
    "    #     for pressure in p_back:\n",
    "    #         if pressure is not None:\n",
    "    #             p_diff[i] -= pressure[0]\n",
    "    #             break\n",
    "# # Close xmdf file\n",
    "# xdmf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Verification using data from FEATFLOW\n",
    "As FEATFLOW has provided data for different  discretization levels, we compare our numerical data with the data provided using `matplotlib`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if rank == 0:\n",
    "#     num_velocity_dofs = V.dofmap.index_map_bs * V.dofmap.index_map.size_global\n",
    "#     num_pressure_dofs = Q.dofmap.index_map_bs * V.dofmap.index_map.size_global\n",
    "    \n",
    "#     turek = np.loadtxt(\"bdforces_lv4\")\n",
    "#     turek_p = np.loadtxt(\"pointvalues_lv4\")\n",
    "#     fig = plt.figure(figsize=(25,8))\n",
    "#     l1 = plt.plot(t_u, C_D, label=r\"FEniCSx  ({0:d} dofs)\".format(num_velocity_dofs+num_pressure_dofs),linewidth=2)\n",
    "#     l2 = plt.plot(turek[1:,1], turek[1:,3], marker=\"x\", markevery=50, \n",
    "#                 linestyle=\"\", markersize=4, label=\"FEATFLOW (42016 dofs)\")\n",
    "#     plt.title(\"Drag coefficient\")\n",
    "#     plt.grid()\n",
    "#     plt.legend()\n",
    "#     plt.savefig(\"drag_Chorin.png\")\n",
    "\n",
    "#     fig = plt.figure(figsize=(25,8))\n",
    "#     l1 = plt.plot(t_u, C_L, label=r\"FEniCSx  ({0:d} dofs)\".format(\n",
    "#         num_velocity_dofs+num_pressure_dofs),linewidth=2)\n",
    "#     l2 = plt.plot(turek[1:,1], turek[1:,4], marker=\"x\", markevery=50, \n",
    "#                 linestyle=\"\", markersize=4, label=\"FEATFLOW (42016 dofs)\")\n",
    "#     plt.title(\"Lift coefficient\")\n",
    "#     plt.grid()\n",
    "#     plt.legend()\n",
    "#     plt.savefig(\"lift_chorin.png\")\n",
    "\n",
    "#     fig = plt.figure(figsize=(25,8))\n",
    "#     l1 = plt.plot(t_p, p_diff, label=r\"FEniCSx ({0:d} dofs)\".format(num_velocity_dofs+num_pressure_dofs),linewidth=2)\n",
    "#     l2 = plt.plot(turek[1:,1], turek_p[1:,6]-turek_p[1:,-1], marker=\"x\", markevery=50, \n",
    "#                 linestyle=\"\", markersize=4, label=\"FEATFLOW (42016 dofs)\")\n",
    "#     plt.title(\"Pressure difference\")\n",
    "#     plt.grid()\n",
    "#     plt.legend()\n",
    "#     plt.savefig(\"pressure_chorin.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe an offset in amplitude. This is due to the reduced number of degrees of freedom compared to FEATFLOW. If we change the parameters `res_min` to `r/5`, and `res_max` to `r`, we can obtain a result closer to the FEATFLOW benchmark. It is recommended to convert the notebook to a python-script using [nbconvert](https://nbconvert.readthedocs.io/en/latest/) and using `mpirun -n 4 python3 ns_code2.py` to run the python program distributed over 4 processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vtk in /usr/local/lib/python3.9/dist-packages (9.1.0)\n",
      "Requirement already satisfied: wslink>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from vtk) (1.4.3)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from vtk) (3.5.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (4.31.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (3.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (9.0.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk) (1.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk) (1.16.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from wslink>=1.0.4->vtk) (3.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (6.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (2.0.12)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk) (1.7.2)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.9/dist-packages (from yarl<2.0,>=1.0->aiohttp->wslink>=1.0.4->vtk) (3.3)\n",
      "Requirement already satisfied: pyvista in /usr/local/lib/python3.9/dist-packages (0.33.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from pyvista) (1.21.5)\n",
      "Requirement already satisfied: vtk in /usr/local/lib/python3.9/dist-packages (from pyvista) (9.1.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from pyvista) (9.0.1)\n",
      "Requirement already satisfied: scooby>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from pyvista) (0.5.12)\n",
      "Requirement already satisfied: appdirs in /usr/local/lib/python3.9/dist-packages (from pyvista) (1.4.4)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.9/dist-packages (from pyvista) (2.16.1)\n",
      "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from vtk->pyvista) (3.5.1)\n",
      "Requirement already satisfied: wslink>=1.0.4 in /usr/local/lib/python3.9/dist-packages (from vtk->pyvista) (1.4.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk->pyvista) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk->pyvista) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk->pyvista) (4.31.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk->pyvista) (1.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk->pyvista) (3.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=2.0.0->vtk->pyvista) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->vtk->pyvista) (1.16.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from wslink>=1.0.4->vtk->pyvista) (3.8.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (1.7.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->wslink>=1.0.4->vtk->pyvista) (2.0.12)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.9/dist-packages (from yarl<2.0,>=1.0->aiohttp->wslink>=1.0.4->vtk->pyvista) (3.3)\n",
      "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.9/dist-packages (3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install vtk\n",
    "!pip install pyvista\n",
    "!pip install pyvirtualdisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os, sys\n",
    "import pyvista\n",
    "import vtk\n",
    "from vtk.util.misc import vtkGetDataRoot\n",
    "# VTK_DATA_ROOT = vtkGetDataRoot()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     fnameIn = \"dfg2D-3.xdmf\"\n",
    "\n",
    "#     xr = vtk.vtkXdmfReader()\n",
    "#     xr.CanReadFile(fnameIn)\n",
    "#     xr.SetFileName(fnameIn)\n",
    "#     xr.UpdateInformation()\n",
    "#     xr.Update()\n",
    "#     ds = xr.GetOutputDataObject(0)\n",
    "#     if not ds:\n",
    "#         print(\"Got zero output from known good file\")\n",
    "#         sys.exit(vtk.VTK_ERROR)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolfinx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bd0afcef7646c8ac2cdb55741d3769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "creating Gif:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(600, 400))\n",
    "display.start()\n",
    "\n",
    "plotter = pyvista.Plotter(notebook=True, window_size=(800,600))\n",
    "\n",
    "plotter.open_gif(\"u_chorin.gif\")\n",
    "\n",
    "progress = tqdm.notebook.tqdm(desc=\"creating Gif\", total=len(list_u))\n",
    "\n",
    "for i in list_u: \n",
    "    progress.update(1)\n",
    "    pyvista_cells, cell_types, coordinates = dolfinx.plot.create_vtk_mesh(i.function_space)\n",
    "    values = i.x.array.reshape(coordinates.shape[0], i.function_space.dofmap.index_map_bs)\n",
    "    grid = pyvista.UnstructuredGrid(pyvista_cells, cell_types, coordinates)\n",
    "    grid.point_data[\"u\"] = values\n",
    "\n",
    "    plotter.add_mesh(grid)\n",
    "    plotter.camera_position = 'xy'\n",
    "    plotter.render()\n",
    "    plotter.write_frame()\n",
    "\n",
    "# Closes and finalizes movie\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a276a745dbf42f1bb2307a78f793b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "creating Gif:   0%|          | 0/160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(600, 400))\n",
    "display.start()\n",
    "\n",
    "plotter = pyvista.Plotter(notebook=True, window_size=(800,600))\n",
    "\n",
    "plotter.open_gif(\"p_chorin.gif\")\n",
    "\n",
    "progress = tqdm.notebook.tqdm(desc=\"creating Gif\", total=len(list_u))\n",
    "\n",
    "for i in list_p: \n",
    "    progress.update(1)\n",
    "    pyvista_cells, cell_types, coordinates = dolfinx.plot.create_vtk_mesh(i.function_space)\n",
    "    values = i.x.array.reshape(coordinates.shape[0], i.function_space.dofmap.index_map_bs)\n",
    "    grid = pyvista.UnstructuredGrid(pyvista_cells, cell_types, coordinates)\n",
    "    grid.point_data[\"u\"] = values\n",
    "\n",
    "    plotter.add_mesh(grid)\n",
    "    plotter.camera_position = 'xy'\n",
    "    plotter.render()\n",
    "    plotter.write_frame()\n",
    "\n",
    "# Closes and finalizes movie\n",
    "plotter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
